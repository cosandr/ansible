---

desktop_label: "{{ hostvars.desktop.inventory_hostname }}"
laptop_label: "{{ hostvars.laptop.inventory_hostname }}"
drepi_label: "{{ hostvars.drepi.inventory_hostname }}"
server_label: "{{ hostvars.dresrv.inventory_hostname }}"
romsto_label: "RomeoTV"
__dresrv: "{{ hostvars['dresrv'] }}"

prometheus_port: 9090
prometheus_storage_retention: "365d"
prometheus_config_flags_extra:
  # Compaction must be disabled for Thanos to work
  "storage.tsdb.min-block-duration": "2h"
  "storage.tsdb.max-block-duration": "2h"
prometheus_web_listen_address: "0.0.0.0:{{ prometheus_port }}"
prometheus_global:
  scrape_interval: 15s
  scrape_timeout: 10s
  evaluation_interval: 15s
prometheus_remote_write:
  - url: "http://127.0.0.1:9201/write"
prometheus_alertmanager_config:
  - scheme: http
    static_configs:
      - targets: ["localhost:{{ alertmanager_web_listen_address.split(':')[1] }}"]

prometheus_node_static_config:
  - targets: ["localhost:{{ node_exporter_port }}"]
    labels:
      instance: "{{ inventory_hostname }}"

  - targets: ["{{ __dresrv.ansible_host }}:{{ __dresrv.node_exporter_port }}"]
    labels:
      instance: "{{ server_label }}"

  - targets: ["{{ hostvars['desktop'].ansible_host }}:{{ hostvars['desktop'].node_exporter_port }}"]
    labels:
      instance: "{{ desktop_label }}"

  - targets: ["{{ hostvars['drepi'].ansible_host }}:{{ hostvars['drepi'].node_exporter_port }}"]
    labels:
      instance: "{{ drepi_label }}"

  - targets: ["{{ hostvars['truenas'].local_ips.vm }}:9100"]
    labels:
      instance: "{{ hostvars['truenas'].inventory_hostname }}"

  - targets: ["{{ hostvars['romsto'].ansible_host }}:{{ hostvars['romsto'].node_exporter_port }}"]
    labels:
      instance: "{{ romsto_label }}"

# Appended at runtime
blackbox_exporter_targets_icmp_ipv4:
  - "google.com"
  - "1.1.1.1"
  - "{{ hostvars['romsto'].ddns_domain }}"
  - "{{ hostvars['webgw01'].ansible_host }}"
  - "{{ hostvars['truenas'].local_ips.vm }}"

blackbox_exporter_targets_http_ipv4:
  - "https://google.com"
  - "https://{{ grafana_domain }}"
prometheus_scrape_configs_runtime: []
# Workaround vars set during role runtime, prometheus_metrics_path for example
prometheus_scrape_configs: "{{ prometheus_scrape_configs_static + prometheus_scrape_configs_runtime }}"
prometheus_scrape_configs_static:
  - job_name: "alertmanager"
    static_configs:
      - targets: ["localhost:{{ alertmanager_web_listen_address.split(':')[1] }}"]
        labels:
          instance: "{{ inventory_hostname }}"

  - job_name: "prometheus"
    metrics_path: "{{ prometheus_metrics_path }}"
    static_configs:
      - targets: ["localhost:{{ prometheus_port }}"]
        labels:
          instance: "{{ inventory_hostname }}"

  - job_name: "pushgateway"
    static_configs:
      - targets: ["localhost:{{ pushgateway_port }}"]
        labels:
          instance: "{{ inventory_hostname }}"

  - job_name: 'thanos'
    static_configs:
      - targets:
          - "localhost:19191"
          - "localhost:19192"
          - "localhost:19193"
          - "localhost:19194"
    relabel_configs:
      - source_labels: [__address__]
        regex: '.*:(\d+)'
        target_label: instance
        replacement: "{{ inventory_hostname }}:${1}"

      - source_labels: [__address__]
        regex: '.*:19191'
        target_label: thanos_svc
        replacement: "sidecar"

      - source_labels: [__address__]
        regex: '.*:19192'
        target_label: thanos_svc
        replacement: "store"

      - source_labels: [__address__]
        regex: '.*:19193'
        target_label: thanos_svc
        replacement: "compact"

      - source_labels: [__address__]
        regex: '.*:19194'
        target_label: thanos_svc
        replacement: "query"

  - job_name: 'vmware_vcenter'
    metrics_path: '/metrics'
    scrape_interval: 1m
    static_configs:
      - targets:
          - "{{ vault_vsphere_host }}"
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: "localhost:{{ vmware_exporter_port }}"

  - job_name: 'blackbox_icmp4'
    metrics_path: '/probe'
    params:
      module: [icmp_ipv4]
    static_configs:
      - targets: "{{ blackbox_exporter_targets_icmp_ipv4 }}"
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: "localhost:{{ blackbox_exporter_port }}"

  - job_name: 'blackbox_http4'
    scrape_interval: 1m
    metrics_path: '/probe'
    params:
      module: [http_2xx_ipv4]
    static_configs:
      - targets: "{{ blackbox_exporter_targets_http_ipv4 }}"
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        replacement: "localhost:{{ blackbox_exporter_port }}"

  - job_name: "ipmi"
    params:
      module: ['default']
    metrics_path: /ipmi
    scrape_interval: 1m
    static_configs:
      - targets: ["localhost:{{ ipmi_exporter_port }}"]
        labels:
          instance: "SLB"
          __param_target: "10.0.100.105"

  - job_name: "mikrotik"
    scrape_interval: 5m
    static_configs:
      - targets: ["localhost:{{ mikrotik_exporter_port }}"]

  - job_name: "cadvisor"
    static_configs:
      - targets: ["{{ __dresrv.ansible_host }}:{{ __dresrv.cadvisor_port }}"]
        labels:
          instance: "{{ server_label }}"

      - targets: ["{{ hostvars['romsto'].ansible_host }}:{{ hostvars['romsto'].cadvisor_port }}"]
        labels:
          instance: "{{ romsto_label }}"

  - job_name: "dht"
    static_configs:
      - targets: ["{{ hostvars['drepi'].ansible_host }}:{{ hostvars['drepi'].dht_exporter_port }}"]
        labels:
          instance: "{{ drepi_label }}"

  - job_name: "bme"
    static_configs:
      - targets:
          - "10.0.50.51:80"
          - "10.0.50.54:80"
          - "10.0.50.55:80"

  - job_name: "node"
    static_configs: "{{ prometheus_node_static_config }}"

  - job_name: "aquaero"
    scrape_interval: 30s
    static_configs:
      - targets: ["{{ hostvars['win-aquaero'].ansible_host }}:{{ hostvars['win-aquaero'].aquaero_exporter_port }}"]
        labels:
          instance: "SLB"
      - targets: ["{{ hostvars['desktop'].ansible_host }}:{{ hostvars['desktop'].aquaero_exporter_port }}"]
        labels:
          instance: "{{ desktop_label }}"

  - job_name: "nvidia"
    scrape_interval: 30s
    static_configs:
      - targets: ["{{ hostvars['desktop'].ansible_host }}:{{ hostvars['desktop'].nvidia_exporter_port }}"]
        labels:
          instance: "{{ desktop_label }}"

  - job_name: "fah"
    scrape_interval: 60s
    static_configs:
      - targets: ["{{ hostvars['desktop'].ansible_host }}:{{ hostvars['desktop'].fah_exporter_port }}"]
        labels:
          instance: "{{ desktop_label }}"

  - job_name: "wmi"
    static_configs:
      - targets: ["{{ hostvars['desktop'].ansible_host }}:{{ hostvars['desktop'].wmi_exporter_port }}"]
        labels:
          instance: "{{ desktop_label }}"

      - targets: ["{{ hostvars['win-aquaero'].ansible_host }}:{{ hostvars['win-aquaero'].wmi_exporter_port }}"]
        labels:
          instance: "{{ hostvars['win-aquaero'].inventory_hostname }}"

  - job_name: "hwinfo"
    static_configs:
      - targets: ["{{ hostvars['desktop'].ansible_host }}:{{ hostvars['desktop'].hwinfo_exporter_port }}"]
        labels:
          instance: "{{ desktop_label }}"

  - job_name: 'postgres'
    scrape_interval: 60s
    static_configs:
      - targets: ["{{ hostvars['pg01'].ansible_host }}:{{ hostvars['pg01'].postgres_exporter_port }}"]
        labels:
          instance: "{{ hostvars['pg01'].inventory_hostname }}"

  - job_name: 'loki'
    static_configs:
      - targets: ["{{ hostvars['loki01'].ansible_host }}:3100"]
        labels:
          instance: "{{ hostvars['loki01'].inventory_hostname }}"

  - job_name: 'nginx'
    scrape_interval: 60s
    static_configs:
      - targets: ['{{ __dresrv.ansible_host }}:{{ __dresrv.nginx_exporter_port }}']
        labels:
          instance: "{{ server_label }}"

      - targets: ["{{ hostvars['webgw01'].wireguard_ip }}:{{ hostvars['webgw01'].nginx_exporter_port }}"]
        labels:
          instance: "{{ hostvars['webgw01'].inventory_hostname }}"

      - targets: ["{{ hostvars['localgw01'].ansible_host }}:{{ hostvars['localgw01'].nginx_exporter_port }}"]
        labels:
          instance: "{{ hostvars['localgw01'].inventory_hostname }}"

      - targets: ["{{ hostvars['romgw01'].wireguard_ip }}:{{ hostvars['romgw01'].nginx_exporter_port }}"]
        labels:
          instance: "{{ hostvars['romgw01'].inventory_hostname }}"

prometheus_alert_rules:
  - alert: HostOutOfMemory
    expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}{{ $labels.instance }} low on memory{% endraw %}'
      description: '{% raw %}Node memory is filling up ({{ printf "%.2f" $value }}% left){% endraw %}'
  - alert: ContainerKilled
    expr: time() - container_last_seen > 60
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}{{ $labels.name }} container dead{% endraw %}'
  - alert: HostSystemdServiceCrashed
    expr: node_systemd_unit_state{state="failed", name!="dnf-makecache.service"} == 1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}{{ $labels.name }} systemd service {{ $labels.state }} on {{ $labels.instance }}{% endraw %}'
  - alert: IpmiCpuTempHigh
    expr: ipmi_temperature_celsius{name="CPU Temp"} > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}CPU Temperature high [{{ $value }}C] on {{ $labels.instance }}{% endraw %}'
  - alert: IpmiVrmTempHigh
    expr: ipmi_temperature_celsius{name=~"VRM.*"} > 90
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}{{ $labels.name }} temperature high [{{ $value }}C] on {{ $labels.instance }}{% endraw %}'
  - alert: IpmiDimmTempHigh
    expr: ipmi_temperature_celsius{name=~"DIMM.*"} > 60
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: '{% raw %}{{ $labels.name }} temperature high [{{ $value }}C] on {{ $labels.instance }}{% endraw %}'
  - alert: InstanceDown
    expr: 'up{instance!="{{ desktop_label }}",instance!="{{ laptop_label }}",job!="mph"} == 0'
    for: 10m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Job {{ $labels.job }} on {{ $labels.instance }} down{% endraw %}'
  - alert: SensorDown
    expr: 'iot_up == 0'
    for: 10m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Sensor {{ $labels.instance }} in room {{ $labels.room }} down{% endraw %}'
  - alert: BmeSensorDown
    expr: '(time() - push_time_seconds{exported_job="bme"}) > 120'
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: '{% raw %}Sensor {{ $labels.exported_instance }} in room {{ $labels.room }} down{% endraw %}'
  - alert: NodeFilesystemSpaceFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up.{% endraw %}'
      summary: 'Filesystem is predicted to run out of space within the next 24 hours.'
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 40\nand\n  predict_linear(node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"}[6h], 24*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemSpaceFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left and is filling up fast.{% endraw %}'
      summary: 'Filesystem is predicted to run out of space within the next 4 hours.'
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 20\nand\n  predict_linear(node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"}[6h], 4*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemAlmostOutOfSpace
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.{% endraw %}'
      summary: 'Filesystem has less than 5% space left.'
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 5\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemAlmostOutOfSpace
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available space left.{% endraw %}'
      summary: 'Filesystem has less than 3% space left.'
    expr: "(\n  node_filesystem_avail_bytes{job=\"node\",fstype!=\"\"} / node_filesystem_size_bytes{job=\"node\",fstype!=\"\"} * 100 < 3\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemFilesFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up.{% endraw %}'
      summary: 'Filesystem is predicted to run out of inodes within the next 24 hours.'
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 40\nand\n  predict_linear(node_filesystem_files_free{job=\"node\",fstype!=\"\"}[6h], 24*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemFilesFillingUp
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left and is filling up fast.{% endraw %}'
      summary: 'Filesystem is predicted to run out of inodes within the next 4 hours.'
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 20\nand\n  predict_linear(node_filesystem_files_free{job=\"node\",fstype!=\"\"}[6h], 4*60*60) < 0\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeFilesystemAlmostOutOfFiles
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.{% endraw %}'
      summary: 'Filesystem has less than 5% inodes left.'
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 5\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeFilesystemAlmostOutOfFiles
    annotations:
      description: '{% raw %}Filesystem on {{ $labels.device }} at {{ $labels.instance }} has only {{ printf "%.2f" $value }}% available inodes left.{% endraw %}'
      summary: 'Filesystem has less than 3% inodes left.'
    expr: "(\n  node_filesystem_files_free{job=\"node\",fstype!=\"\"} / node_filesystem_files{job=\"node\",fstype!=\"\"} * 100 < 3\nand\n  node_filesystem_readonly{job=\"node\",fstype!=\"\"} == 0\n)\n"
    for: 1h
    labels:
      severity: critical
  - alert: NodeNetworkReceiveErrs
    annotations:
      description: '{% raw %}{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} receive errors in the last two minutes.{% endraw %}'
      summary: 'Network interface is reporting many receive errors.'
    expr: "increase(node_network_receive_errs_total[2m]) > 10\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeNetworkTransmitErrs
    annotations:
      description: '{% raw %}{{ $labels.instance }} interface {{ $labels.device }} has encountered {{ printf "%.0f" $value }} transmit errors in the last two minutes.{% endraw %}'
      summary: 'Network interface is reporting many transmit errors.'
    expr: "increase(node_network_transmit_errs_total[2m]) > 10\n"
    for: 1h
    labels:
      severity: warning
  - alert: NodeHighNumberConntrackEntriesUsed
    annotations:
      description: '{% raw %}{{ $value | humanizePercentage }} of conntrack entries are used{% endraw %}'
      summary: 'Number of conntrack are getting close to the limit'
    expr: "(node_nf_conntrack_entries / node_nf_conntrack_entries_limit) > 0.75\n"
    labels:
      severity: warning
  - alert: NodeClockSkewDetected
    annotations:
      message: '{% raw %}Clock on {{ $labels.instance }} is out of sync by more than 300s. Ensure NTP is configured correctly on this host.{% endraw %}'
      summary: 'Clock skew detected.'
    expr: "(\n  node_timex_offset_seconds > 0.05\nand\n  deriv(node_timex_offset_seconds[5m]) >= 0\n)\nor\n(\n  node_timex_offset_seconds < -0.05\nand\n  deriv(node_timex_offset_seconds[5m]) <= 0\n)\n"
    for: 10m
    labels:
      severity: warning
  - alert: NodeClockNotSynchronising
    annotations:
      message: '{% raw %}Clock on {{ $labels.instance }} is not synchronising. Ensure NTP is configured on this host.{% endraw %}'
      summary: 'Clock not synchronising.'
    expr: "min_over_time(node_timex_sync_status[5m]) == 0\n"
    for: 10m
    labels:
      severity: warning
